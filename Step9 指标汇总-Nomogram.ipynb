{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321dd425",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import onekey_algo.custom.components as okcomp\n",
    "from onekey_algo import get_param_in_cwd\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '{: .3f}'.format(x))\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "model_names = ['CEA', 'Pathology', 'Combined']\n",
    "model_labels = ['Clincal model', 'Pathology model', 'Combined model']\n",
    "# model_names = ['CEA', 'Pathology']\n",
    "# 获取配置\n",
    "task = get_param_in_cwd('task_column') or 'label'\n",
    "bst_model = 'XGBoost'\n",
    "clinic_model = 'ExtraTrees'\n",
    "labelf = get_param_in_cwd('label_file')\n",
    "group_info = get_param_in_cwd('dataset_column') or 'group'\n",
    "\n",
    "# 读取label文件。\n",
    "labels = [task]\n",
    "label_data_ = pd.read_csv(labelf)\n",
    "label_data_['ID'] = label_data_['ID'].astype(str)\n",
    "label_data_ = label_data_[['ID', group_info, task]]\n",
    "label_data_ = label_data_.dropna(axis=0)\n",
    "\n",
    "ids = label_data_['ID']\n",
    "print(label_data_.columns)\n",
    "label_data = label_data_[['ID'] + labels]\n",
    "label_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5ee2cf",
   "metadata": {},
   "source": [
    "# 训练集-Nomogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5002786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "subset = 'train'\n",
    "Clinic_results = pd.read_csv(f'clinic_sel.csv', header=0)[['ID', 'CEA']]\n",
    "Clinic_results['ID'] = Clinic_results['ID'].astype(str)\n",
    "Clinic_results['CEA'] = Clinic_results['CEA'] / np.max(Clinic_results['CEA'])\n",
    "Clinic_results['CEA-0'] = 1 - Clinic_results['CEA']\n",
    "Clinic_results = pd.merge(Clinic_results, label_data, on='ID', how='inner')\n",
    "Path_results = pd.read_csv(f'./results/Path_{bst_model}_{subset}.csv', header=0)\n",
    "Path_results['ID'] = Path_results['ID'].astype(str)\n",
    "Path_results = pd.merge(Path_results, label_data, on='ID', how='inner')\n",
    "\n",
    "ALL_results = pd.merge(Clinic_results, Path_results, on='ID', how='inner')\n",
    "ALL_results.columns = ['ID', '-0', 'CEA', task, '-00', 'Pathology', '-ll']\n",
    "# Clinical = pd.read_csv('clinic_sel.csv')[['ID', 'Smoking', 'Diabetes', 'Triglycerides', \"eGFR\", 'label']]\n",
    "# Clinical['ID'] = Clinical['ID'].astype(str)\n",
    "Clinic_results = pd.merge(ALL_results[['ID']], Clinic_results, on='ID', how='inner')\n",
    "\n",
    "ALL_results = ALL_results.dropna(axis=1)\n",
    "ALL_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07de275b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from onekey_algo.custom.components import metrics\n",
    "\n",
    "mnames = ['SVM', 'KNN', 'ExtraTrees', 'XGBoost', 'MLP', 'LR', 'nb', 'AdaBoost']\n",
    "models = okcomp.comp1.create_clf_model(mnames)\n",
    "mnames = list(models.keys())\n",
    "\n",
    "model = LogisticRegression(penalty='none')\n",
    "# model = SVC(probability=True, random_state=0)\n",
    "data_x = ALL_results[['CEA', 'Pathology']]\n",
    "data_y = ALL_results[task]\n",
    "model.fit(data_x, data_y)\n",
    "results = model.predict_proba(data_x)\n",
    "results = pd.DataFrame(results, index=ALL_results['ID'], columns=[f'{task}-0', f'{task}-1']).reset_index()\n",
    "results.to_csv(f'./results/Nomo_{subset}.csv', index=False, header=True)\n",
    "pd.DataFrame([metrics.analysis_pred_binary(ALL_results[task], results[f'{task}-1'])], \n",
    "                  columns=['acc', 'auc', '95%CI', 'Sensitivity', 'Specificity', 'PPV', 'NPV', 'Precision', 'Recall', 'F1', 'Threshold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e04731e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pred_column = [f'{task}-0', f'{task}-1']\n",
    "Nomo_results = pd.read_csv(f'./results/Nomo_{subset}.csv', header=0)\n",
    "Nomo_results['ID'] = Nomo_results['ID'].astype(str)\n",
    "Nomo_results = pd.merge(Nomo_results, label_data, on='ID', how='inner')\n",
    "gt = [np.array(d) for d in [Clinic_results[labels], \n",
    "                            Path_results[labels],\n",
    "                            Nomo_results[labels]]]\n",
    "pred_train = [np.array(d) for d in [Clinic_results[['CEA-0', 'CEA']], \n",
    "                                    Path_results[pred_column],\n",
    "                                    Nomo_results[pred_column]]]\n",
    "okcomp.comp1.draw_roc(gt, pred_train, labels=model_labels, title=f\"Model AUC\")\n",
    "plt.savefig(f'img/{subset}_auc.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4826febd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from onekey_algo.custom.components.metrics import analysis_pred_binary\n",
    "metric = []\n",
    "for mname, y, score in zip(model_names, gt, pred_train):\n",
    "    # 计算验证集指标\n",
    "    acc, auc, ci, tpr, tnr, ppv, npv, precision, recall, f1, thres = analysis_pred_binary(y, score, use_youden=True)\n",
    "    ci = f\"{ci[0]:.4f} - {ci[1]:.4f}\"\n",
    "    metric.append((mname, acc, auc, ci, tpr, tnr, ppv, npv, precision, recall, f1, thres, f\"Train\"))\n",
    "pd.DataFrame(metric, index=None, columns=['Signature', 'Accuracy', 'AUC', '95% CI', 'Sensitivity', 'Specificity', \n",
    "                                          'PPV', 'NPV', 'Precision', 'Recall', 'F1','Threshold', 'Cohort'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69899f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from onekey_algo.custom.components.delong import delong_roc_test\n",
    "\n",
    "Nomo_results.columns = ['ID', '-00000', 'Combined', '-llll']\n",
    "ALL_results = pd.merge(ALL_results, Nomo_results, on='ID', how='inner')\n",
    "\n",
    "delong = []\n",
    "\n",
    "this_delong = []\n",
    "delong_columns = []\n",
    "for i, mni in enumerate(model_names):\n",
    "    for _, mnj in enumerate(model_names[i+1:]):\n",
    "        this_delong.append(delong_roc_test(ALL_results[task], ALL_results[mni], ALL_results[mnj])[0][0])\n",
    "        delong_columns.append(f\"{mni} Vs {mnj}\")\n",
    "this_delong.append('Train')\n",
    "delong_columns.append('cohort')\n",
    "delong.append(this_delong)\n",
    "pd.DataFrame(this_delong, index=delong_columns).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4045192a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from onekey_algo.custom.components.comp1 import plot_DCA\n",
    "plot_DCA([\n",
    "          ALL_results[f'Pathology'],\n",
    "          ALL_results[f'Combined']], \n",
    "         ALL_results[task], title=f'Model for DCA', labels=[f\"{m} model\" for m in model_names[1:]], y_min=-0.15)\n",
    "plt.savefig(f'img/{subset}_dca.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c40079",
   "metadata": {},
   "outputs": [],
   "source": [
    "from onekey_algo.custom.components.comp1 import draw_calibration\n",
    "draw_calibration(pred_scores=pred_train[1:], n_bins=5, remap=True, #EX={'n_estimators': 10, 'max_depth': 4}, #smooth=True, # window_length=15, k=3,\n",
    "                 y_test=gt[1:], model_names=model_labels[1:])\n",
    "plt.savefig(f'img/{subset}_cali.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec7e842",
   "metadata": {},
   "outputs": [],
   "source": [
    "from onekey_algo.custom.components import stats\n",
    "\n",
    "hosmer = []\n",
    "hosmer.append([stats.hosmer_lemeshow_test(y_true, y_pred[:,1], bins=5) \n",
    "              for fn, y_true, y_pred in zip(model_names, gt, pred_train)])\n",
    "pd.DataFrame(hosmer, columns=model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49a1a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from onekey_algo.custom.components.comp1 import normalize_df\n",
    "ALL_results = normalize_df(ALL_results, not_norm=['CEA', 'label', 'ID'], method='minmax')\n",
    "ALL_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497e7a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from onekey_algo.custom.components import nomogram\n",
    "import shutil\n",
    "\n",
    "ALL_results['CEA'] = ALL_results['CEA'] * 3\n",
    "nomogram.risk_nomogram(ALL_results, result=task, columns=['CEA', 'Pathology'], \n",
    "                       width=8000, height=4000, x_range='0.05,0.25,0.50,0.75,0.95')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd19d5c",
   "metadata": {},
   "source": [
    "# 测试集-Nomogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e08e9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "subset = 'test'\n",
    "\n",
    "Clinic_results = pd.read_csv(f'clinic_sel.csv', header=0)[['ID', model_names[0]]]\n",
    "Clinic_results['ID'] = Clinic_results['ID'].astype(str)\n",
    "Clinic_results['CEA'] = Clinic_results['CEA'] / np.max(Clinic_results['CEA'])\n",
    "Clinic_results['CEA-0'] = 1 - Clinic_results['CEA']\n",
    "Clinic_results = pd.merge(Clinic_results, label_data, on='ID', how='inner')\n",
    "Path_results = pd.read_csv(f'./results/Path_{bst_model}_{subset}.csv', header=0)\n",
    "Path_results['ID'] = Path_results['ID'].astype(str)\n",
    "Path_results = pd.merge(Path_results, label_data, on='ID', how='inner')\n",
    "\n",
    "ALL_results = pd.merge(Clinic_results, Path_results, on='ID', how='inner')\n",
    "ALL_results.columns = ['ID', '-0', 'CEA', task, '-00', 'Pathology', '-ll']\n",
    "# Clinical = pd.read_csv('clinic_sel.csv')[['ID', 'Smoking', 'Diabetes', 'Triglycerides', \"eGFR\", 'label']]\n",
    "# Clinical['ID'] = Clinical['ID'].astype(str)\n",
    "Clinic_results = pd.merge(ALL_results[['ID']], Clinic_results, on='ID', how='inner')\n",
    "\n",
    "ALL_results = ALL_results.dropna(axis=1)\n",
    "ALL_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72447b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from onekey_algo.custom.components import metrics\n",
    "\n",
    "model = LogisticRegression(random_state=0, penalty='none')\n",
    "# model = SVC(probability=True, random_state=0)\n",
    "\n",
    "# ALL_results = normalize_df(ALL_results, not_norm=['CEA', 'label', 'ID'], method='minmax')\n",
    "data_x = ALL_results[['CEA', 'Pathology']]\n",
    "data_y = ALL_results[task]\n",
    "model.fit(data_x, data_y)\n",
    "results = model.predict_proba(data_x)\n",
    "results = pd.DataFrame(results, index=ALL_results['ID'], columns=[f'{task}-0', f'{task}-1']).reset_index()\n",
    "results.to_csv(f'./results/Nomo_{subset}.csv', index=False, header=True)\n",
    "pd.DataFrame([metrics.analysis_pred_binary(ALL_results[task], results[f'{task}-1'])], \n",
    "                  columns=['acc', 'auc', '95%CI', 'Sensitivity', 'Specificity', 'PPV', 'NPV', 'Precision', 'Recall', 'F1', 'Threshold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67328a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_column = [f'{task}-0', f'{task}-1']\n",
    "Nomo_results = pd.read_csv(f'./results/Nomo_{subset}.csv', header=0)\n",
    "Nomo_results['ID'] = Nomo_results['ID'].astype(str)\n",
    "Nomo_results = pd.merge(Nomo_results, label_data, on='ID', how='inner')\n",
    "gt = [np.array(d) for d in [Clinic_results[labels], \n",
    "                            Path_results[labels],\n",
    "                            Nomo_results[labels]]]\n",
    "pred_train = [np.array(d) for d in [Clinic_results[['CEA-0', 'CEA']], \n",
    "                                    Path_results[pred_column],\n",
    "                                    Nomo_results[pred_column]]]\n",
    "okcomp.comp1.draw_roc(gt, pred_train, labels=[f\"{m}\" for m in model_labels], title=f\"Model AUC\")\n",
    "plt.savefig(f'img/{subset}_auc.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc97fa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from onekey_algo.custom.components.metrics import analysis_pred_binary\n",
    "for mname, y, score in zip(model_names, gt, pred_train):\n",
    "    # 计算验证集指标\n",
    "    acc, auc, ci, tpr, tnr, ppv, npv, precision, recall, f1, thres = analysis_pred_binary(y, score)\n",
    "    ci = f\"{ci[0]:.4f} - {ci[1]:.4f}\"\n",
    "    metric.append((mname, acc, auc, ci, tpr, tnr, ppv, npv, precision, recall, f1, thres, f\"Test\"))\n",
    "pd.DataFrame(metric, index=None, columns=['Signature', 'Accuracy', 'AUC', '95% CI',\n",
    "                                          'Sensitivity', 'Specificity', \n",
    "                                          'PPV', 'NPV', 'Precision', 'Recall', 'F1', 'Threshold', 'Cohort'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff64306d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from onekey_algo.custom.components.delong import delong_roc_test\n",
    "\n",
    "Nomo_results.columns = ['ID', '-00000', 'Combined', '-llll']\n",
    "ALL_results = pd.merge(ALL_results, Nomo_results, on='ID', how='inner')\n",
    "\n",
    "this_delong = []\n",
    "delong_columns = []\n",
    "for i, mni in enumerate(model_names):\n",
    "    for _, mnj in enumerate(model_names[i+1:]):\n",
    "        this_delong.append(delong_roc_test(ALL_results[task], ALL_results[mni], ALL_results[mnj])[0][0])\n",
    "        delong_columns.append(f\"{mni} Vs {mnj}\")\n",
    "this_delong.append('Test')\n",
    "delong_columns.append('cohort')\n",
    "delong.append(this_delong)\n",
    "pd.DataFrame(delong, columns=delong_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadf93ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from onekey_algo.custom.components.comp1 import plot_DCA\n",
    "plot_DCA([\n",
    "          ALL_results[f'Pathology'],\n",
    "          ALL_results[f'Combined']], \n",
    "         ALL_results[task], title=f'Model for DCA', labels=[f\"{m} model\" for m in model_names[1:]], y_min=-0.2)\n",
    "plt.savefig(f'img/{subset}_dca.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5f2d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from onekey_algo.custom.components.comp1 import draw_calibration\n",
    "draw_calibration(pred_scores=pred_train[1:], n_bins=5, remap=True, #EX={'n_estimators': 10, 'max_depth': 4}, #smooth=True, # window_length=15, k=3,\n",
    "                 y_test=gt[1:], model_names=model_labels[1:])\n",
    "plt.savefig(f'img/{subset}_cali.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9aebe4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from onekey_algo.custom.components import stats\n",
    "\n",
    "hosmer.append([stats.hosmer_lemeshow_test(y_true, y_pred[:,1], bins=5) \n",
    "              for fn, y_true, y_pred in zip(model_names, gt, pred_train)])\n",
    "pd.DataFrame(hosmer, columns=model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d691507b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
